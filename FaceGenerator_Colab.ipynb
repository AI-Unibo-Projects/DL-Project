{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "FaceGenerator_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds9LpNYOOYHq",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI-Unibo-Projects/Deep-Learning-Project/blob/4_model/FaceGenerator_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QrprJD-R-410"
      },
      "source": [
        "## Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_I0RdnOSkNmi"
      },
      "source": [
        "\n",
        "<h3>  &nbsp;&nbsp;Train on TPU&nbsp;&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a></h3>\n",
        "\n",
        "   1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "   1. Click Runtime again and select **Runtime > Run All**. You can also run the cells manually with Shift-ENTER. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "We'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-RCipesOYHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "tf.keras.backend.clear_session()  # For easy reset of notebook state.\"\"\"\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "    \n",
        "config = tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "batch_size = 16 * tpu_strategy.num_replicas_in_sync\n",
        "buffer_size = 60000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vFIMfPmgQa0h",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kvPXiovhi3ZZ"
      },
      "source": [
        "\n",
        "## Input data\n",
        "\n",
        "Our input data is stored on Google Cloud Storage. To more fully use the parallelism TPUs offer us, and to avoid bottlenecking on data transfer, we've stored our input data in TFRecord files, 2025 images per file.\n",
        "\n",
        "Below, we make heavy use of `tf.data.experimental.AUTOTUNE` to optimize different parts of input loading.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LtAVr-4CP1rp",
        "colab": {}
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "IMAGE_SIZE = [64, 64]\n",
        "\n",
        "gcs_pattern = 'gs://celeba-public/tfrecord_*.tfrec'\n",
        "\n",
        "filenames = tf.io.gfile.glob(gcs_pattern)\n",
        "\n",
        "def parse_attribute_list(example):\n",
        "  features = {\n",
        "      \"names\": tf.io.FixedLenFeature([], tf.string),\n",
        "  }\n",
        "\n",
        "  example = tf.io.parse_single_example(example, features)\n",
        "  attributes_names = example['names']\n",
        "  return attributes_names\n",
        "\n",
        "def get_names():\n",
        "  record = tf.data.TFRecordDataset('gs://celeba-test/attribute_list.tfrec')\n",
        "  attributes = record.map(parse_attribute_list)\n",
        "  att_names = next(attributes.as_numpy_iterator()).decode(\"utf-8\")\n",
        "  att_names_list = [elem.strip()[1:-1] for elem in att_names.split(',')]\n",
        "  return att_names_list\n",
        "\n",
        "att_names_list = get_names()\n",
        "\n",
        "\n",
        "feature_dict = {\n",
        "      \"filename\": tf.io.FixedLenFeature([], tf.string),\n",
        "      \"height\": tf.io.FixedLenFeature([], tf.int64),\n",
        "      \"width\": tf.io.FixedLenFeature([], tf.int64),\n",
        "      \"depth\": tf.io.FixedLenFeature([], tf.int64),\n",
        "      \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "  }\n",
        "\n",
        "attributes_dict = dict(zip(att_names_list, [tf.io.FixedLenFeature([], tf.int64) for elem in att_names_list]))\n",
        "\n",
        "feature_dict.update(attributes_dict) \n",
        "\n",
        "def parse_tfrecord(example):\n",
        "  features = feature_dict\n",
        "  example = tf.io.parse_single_example(example, features)\n",
        "  #filename = example['filename']\n",
        "  width = tf.cast(example['width'],tf.int64)\n",
        "  height = tf.cast(example['height'],tf.int64)\n",
        "  decoded = tf.image.decode_image(example['image'])  \n",
        "  normalized = tf.cast(decoded, tf.float32) / 255.0 # convert each 0-255 value to floats in [0, 1] range\n",
        "  image_tensor = tf.reshape(normalized, [height, width, 3])\n",
        "  image_tensor = tf.image.resize(image_tensor[45:173,25:153], IMAGE_SIZE) # crop and reshape the image \n",
        "  #attr_dict = {}\n",
        "  #for name in att_names_list:\n",
        "  #  attr_dict[name] = example[name]\n",
        "\n",
        "  #Â return filename, image_tensor, attr_dict\n",
        "  return image_tensor\n",
        "\n",
        "def load_dataset(filenames):\n",
        "  # Read from TFRecords. For optimal performance, we interleave reads from multiple files.\n",
        "  records = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "  return records.map(parse_tfrecord, num_parallel_calls=AUTO)\n",
        "\n",
        "dataset = load_dataset(filenames).batch(batch_size)\n",
        "dataset.shuffle(buffer_size)\n",
        "print(type(dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KTukaIGil7_m"
      },
      "source": [
        "Let's take a peek at the dataset we've created:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-DwfsJq0l_DJ",
        "colab": {}
      },
      "source": [
        "def display_images(images, n):\n",
        "  plt.figure(figsize=(13,13))\n",
        "  for i in range(n * n):\n",
        "    # define subplot\n",
        "    plt.subplot(n, n, i+1)\n",
        "    # turn off axis\n",
        "    plt.axis('off')\n",
        "    plt.imshow(images[i])\n",
        "  plt.tight_layout()\n",
        "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def get_dataset_iterator(dataset, n_examples):\n",
        "  return dataset.unbatch().batch(n_examples).as_numpy_iterator()\n",
        "\n",
        "training_viz_iterator = get_dataset_iterator(dataset, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JTnyd7qfbYr4",
        "colab": {}
      },
      "source": [
        "\"\"\"# Re-run this cell to show a new batch of images\n",
        "name, images, attr = next(training_viz_iterator)\n",
        "print('Image name {}\\n'.format(name[0]))\n",
        "for name in attr.keys():\n",
        "  print('{}: {}\\n'.format(name, attr[name][0]))\n",
        "display_images(images, 10)\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ALtRUlxhw8Vt"
      },
      "source": [
        "## Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIeUXmrvQ8AT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_generator():\n",
        "  # Generator using Functional API\n",
        "\n",
        "  # Input layer\n",
        "  input_layer = layers.Input(shape=(100,))\n",
        "  x = layers.Dense(8*8*256, use_bias=False)(input_layer) # input_shape is the noise seed\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "\n",
        "  # Reshape input\n",
        "  reshape = layers.Reshape((8, 8, 256))\n",
        "  x = reshape(x)\n",
        "  # assert reshape.output_shape == (None, 8, 8, 256) # Note: None is the batch size\n",
        "  \n",
        "  # First upscale layer\n",
        "  conv2dtranspose_1 = layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)\n",
        "  x = conv2dtranspose_1(x)\n",
        "  # assert conv2dtranspose_1.output_shape == (None, 8, 8, 128)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "\n",
        "  # Second upscale layer\n",
        "  conv2dtranspose_2 = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
        "  x = conv2dtranspose_2(x)\n",
        "  # assert conv2dtranspose_2.output_shape == (None, 16, 16, 64)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  \n",
        "  # Third upscale layer\n",
        "  conv2dtranspose_3 = layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
        "  x = conv2dtranspose_3(x)\n",
        "  # assert conv2dtranspose_3.output_shape == (None, 32, 32, 32)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "\n",
        "  # Fourth upscale layer\n",
        "  conv2dtranspose_4 = layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
        "  x = conv2dtranspose_4(x)\n",
        "  # assert conv2dtranspose_4.output_shape == (None, 64, 64, 3)\n",
        "\n",
        "  # Output layer  \n",
        "  output_layer = layers.Activation(activation='tanh')(x)\n",
        "\n",
        "  # Create and compile generator model\n",
        "  model = tf.keras.Model(inputs=[input_layer], outputs=[output_layer], name=\"generator\")\n",
        "  # model.compile(loss=generator_loss, optimizer=generator_optimizer)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ao7HxRo6Sw3E",
        "colab": {}
      },
      "source": [
        "def create_discriminator():\n",
        "  # Discriminator using Functional API\n",
        "\n",
        "  # Input layer\n",
        "  input_layer = layers.Input(shape=(64, 64, 3))\n",
        "  \n",
        "  # First Convolutional Layer\n",
        "  x = layers.Conv2D(filters=64, kernel_size=(5, 5), strides=(2, 2), padding='same')(input_layer)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "\n",
        "  # Second Convolutional Layer\n",
        "  x = layers.Conv2D(filters=128, kernel_size=(5, 5), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "\n",
        "  # Third Convolutional Layer\n",
        "  x = layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "\n",
        "  # Flatten Layer\n",
        "  x = layers.Flatten()(x)\n",
        "\n",
        "  # Output Layer\n",
        "  output_layer= layers.Dense(1)(x)\n",
        "\n",
        "  # Create and Compile Model\n",
        "  model = tf.keras.Model(inputs=[input_layer], outputs=[output_layer], name=\"discriminator\")\n",
        "  # model.compile(loss=discriminator_loss, optimizer=discriminator_optimizer)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F2VeZUWUj5S4",
        "colab": {}
      },
      "source": [
        "def loss(model, x, y):\n",
        "  \"\"\"Calculates the loss given an example (x, y)\"\"\"\n",
        "  logits = model(x)\n",
        "  return logits, tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits)\n",
        "\n",
        "def grad(model, x, y):\n",
        "  \"\"\"Calculates the loss and the gradients given an example (x, y)\"\"\"\n",
        "  logits, loss_value = loss(model, x, y)\n",
        "  return logits, loss_value, tf.gradients(loss_value, model.trainable_variables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwYdS0NrZRhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Binary crossentropy losses for generator and discriminator\n",
        "\n",
        "with tpu_strategy.scope():\n",
        "  def generator_loss(fake_output):\n",
        "    return tf.keras.losses.binary_crossentropy(tf.ones_like(fake_output), fake_output, from_logits=True)\n",
        "\n",
        "  def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(real_output), real_output, from_logits=True)\n",
        "    fake_loss = tf.keras.losses.binary_crossentropy(tf.zeros_like(fake_output), fake_output, from_logits=True)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I3CCF77cTrmv",
        "colab": {}
      },
      "source": [
        "# Testing generator and discriminator without training\n",
        "with tpu_strategy.scope(): # Train on TPU\n",
        "  generator = create_generator() # Create generator model\n",
        "  discriminator = create_discriminator() # Create discriminator model\n",
        "  generator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "  discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "# Generate random noise bewteen 1 and 100\n",
        "noise = tf.random.normal([1, 100])\n",
        "\n",
        "# Generate a random image\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "# Plot the generated image\n",
        "plt.imshow(generated_image[0, :, :, 0]) \n",
        "\n",
        "# Discriminate the generated image\n",
        "decision = discriminator(generated_image)\n",
        "\n",
        "# Print the discriminator decision\n",
        "print(decision)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOtq3Y_CjC-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print a summary of the generator model\n",
        "generator.summary()\n",
        "tf.keras.utils.plot_model(generator, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WuafnkLjLIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print a summary of the discriminator model\n",
        "discriminator.summary()\n",
        "tf.keras.utils.plot_model(discriminator, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jueOuDOZhK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"checkpoint_dir = '/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dMfenMQcxAAb"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lkUcBU8xS3fT",
        "colab": {}
      },
      "source": [
        "epochs = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# We will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUJmQebDZ2Z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "\n",
        "@tf.function\n",
        "def train_step(iterator):\n",
        "  def step_fn(inputs):\n",
        "    noise = tf.random.normal([batch_size, noise_dim])\n",
        "    images = inputs\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training = True)\n",
        "      fake_output = discriminator(generated_images, training = True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "      gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    return gradients_of_generator,gradients_of_discriminator\n",
        "\n",
        "  return tpu_strategy.run(\n",
        "      step_fn, args=(next(iterator),))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbGZ15OZnGw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    train_step(iter(dataset))\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhFwj6IMnLd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(dataset,100)\n",
        "#print(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpd6gAksx5na",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_image = generator(seed, training=False)\n",
        "\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0]) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}