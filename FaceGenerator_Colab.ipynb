{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "FaceGenerator_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds9LpNYOOYHq",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI-Unibo-Projects/Deep-Learning-Project/blob/4_model/FaceGenerator_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QrprJD-R-410"
      },
      "source": [
        "## Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_I0RdnOSkNmi"
      },
      "source": [
        "\n",
        "<h3>  &nbsp;&nbsp;Train on TPU&nbsp;&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a></h3>\n",
        "\n",
        "   1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "   1. Click Runtime again and select **Runtime > Run All**. You can also run the cells manually with Shift-ENTER. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "We'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-RCipesOYHu",
        "colab_type": "code",
        "outputId": "2c768b7c-832e-4b72-8b71-252bfa920110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"is_colab = True\n",
        "try:\n",
        "    import google.colab\n",
        "except:\n",
        "    is_colab = False\"\"\"\n",
        "\n",
        "is_colab = False\n",
        "    \n",
        "if is_colab:\n",
        "    %tensorflow_version 2.x\n",
        "    import tensorflow as tf\n",
        "    print(\"Tensorflow version \" + tf.__version__)\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "    except ValueError:\n",
        "        raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "        \n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    batch_size = 16 * tpu_strategy.num_replicas_in_sync\n",
        "else:\n",
        "    import tensorflow as tf\n",
        "    print(\"Tensorflow version \" + tf.__version__)\n",
        "    batch_size = 16\n",
        "\n",
        "buffer_size = 60000\n",
        "tf.keras.backend.clear_session()  # For easy reset of notebook state."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vFIMfPmgQa0h",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kvPXiovhi3ZZ"
      },
      "source": [
        "\n",
        "## Input data\n",
        "\n",
        "Our input data is stored on Google Cloud Storage. To more fully use the parallelism TPUs offer us, and to avoid bottlenecking on data transfer, we've stored our input data in TFRecord files, 2025 images per file.\n",
        "\n",
        "Below, we make heavy use of `tf.data.experimental.AUTOTUNE` to optimize different parts of input loading.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LtAVr-4CP1rp",
        "outputId": "8796dc35-2ab7-428a-8827-6a8cfc9caee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "IMAGE_SIZE = [64, 64]\n",
        "\n",
        "gcs_pattern = 'gs://celeba-public/tfrecord_*.tfrec'\n",
        "\n",
        "filenames = tf.io.gfile.glob(gcs_pattern)\n",
        "\n",
        "def parse_attribute_list(example):\n",
        "  features = {\n",
        "      \"names\": tf.io.FixedLenFeature([], tf.string),\n",
        "  }\n",
        "\n",
        "  example = tf.io.parse_single_example(example, features)\n",
        "  attributes_names = example['names']\n",
        "  return attributes_names\n",
        "\n",
        "def get_names():\n",
        "  record = tf.data.TFRecordDataset('gs://celeba-test/attribute_list.tfrec')\n",
        "  attributes = record.map(parse_attribute_list)\n",
        "  att_names = next(attributes.as_numpy_iterator()).decode(\"utf-8\")\n",
        "  att_names_list = [elem.strip()[1:-1] for elem in att_names.split(',')]\n",
        "  return att_names_list\n",
        "\n",
        "att_names_list = get_names()\n",
        "\n",
        "\n",
        "feature_dict = {\n",
        "      \"filename\": tf.io.FixedLenFeature([], tf.string),\n",
        "      \"height\": tf.io.FixedLenFeature([], tf.int64),\n",
        "      \"width\": tf.io.FixedLenFeature([], tf.int64),\n",
        "      \"depth\": tf.io.FixedLenFeature([], tf.int64),\n",
        "      \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "  }\n",
        "\n",
        "attributes_dict = dict(zip(att_names_list, [tf.io.FixedLenFeature([], tf.int64) for elem in att_names_list]))\n",
        "\n",
        "feature_dict.update(attributes_dict) \n",
        "\n",
        "def parse_tfrecord(example):\n",
        "  features = feature_dict\n",
        "  example = tf.io.parse_single_example(example, features)\n",
        "  #filename = example['filename']\n",
        "  width = tf.cast(example['width'],tf.int64)\n",
        "  height = tf.cast(example['height'],tf.int64)\n",
        "  decoded = tf.image.decode_image(example['image'])  \n",
        "  normalized = tf.cast(decoded, tf.float32) / 255.0 # convert each 0-255 value to floats in [0, 1] range\n",
        "  image_tensor = tf.reshape(normalized, [height, width, 3])\n",
        "  image_tensor = tf.image.resize(image_tensor[45:173,25:153], IMAGE_SIZE) # crop and reshape the image \n",
        "  #attr_dict = {}\n",
        "  #for name in att_names_list:\n",
        "  #  attr_dict[name] = example[name]\n",
        "\n",
        "  #Â return filename, image_tensor, attr_dict\n",
        "  return image_tensor\n",
        "\n",
        "def load_dataset(filenames):\n",
        "  # Read from TFRecords. For optimal performance, we interleave reads from multiple files.\n",
        "  records = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "  return records.map(parse_tfrecord, num_parallel_calls=AUTO)\n",
        "\n",
        "dataset = load_dataset(filenames).batch(batch_size)\n",
        "dataset.shuffle(buffer_size)\n",
        "print(type(dataset))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KTukaIGil7_m"
      },
      "source": [
        "Let's take a peek at the dataset we've created:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-DwfsJq0l_DJ",
        "colab": {}
      },
      "source": [
        "def display_images(images, n):\n",
        "  plt.figure(figsize=(13,13))\n",
        "  for i in range(n * n):\n",
        "    # define subplot\n",
        "    plt.subplot(n, n, i+1)\n",
        "    # turn off axis\n",
        "    plt.axis('off')\n",
        "    plt.imshow(images[i])\n",
        "  plt.tight_layout()\n",
        "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def get_dataset_iterator(dataset, n_examples):\n",
        "  return dataset.unbatch().batch(n_examples).as_numpy_iterator()\n",
        "\n",
        "training_viz_iterator = get_dataset_iterator(dataset, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JTnyd7qfbYr4",
        "outputId": "5cd1d4d8-85cb-48ed-c520-a9fb717d88ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"# Re-run this cell to show a new batch of images\n",
        "name, images, attr = next(training_viz_iterator)\n",
        "print('Image name {}\\n'.format(name[0]))\n",
        "for name in attr.keys():\n",
        "  print('{}: {}\\n'.format(name, attr[name][0]))\n",
        "display_images(images, 10)\"\"\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"# Re-run this cell to show a new batch of images\\nname, images, attr = next(training_viz_iterator)\\nprint('Image name {}\\n'.format(name[0]))\\nfor name in attr.keys():\\n  print('{}: {}\\n'.format(name, attr[name][0]))\\ndisplay_images(images, 10)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ALtRUlxhw8Vt"
      },
      "source": [
        "## Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwYdS0NrZRhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Binary crossentropy losses for generator and discriminator\n",
        "\n",
        "#with tpu_strategy.scope():\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  total_loss = real_loss + fake_loss\n",
        "  return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W46LXIBNZa5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define generator and discriminator optimizers\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIeUXmrvQ8AT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_generator():\n",
        "  \"\"\"\n",
        "  Generator using Sequential Model\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(100,))) # input_shape is the noise seed\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Reshape((8, 8, 256)))\n",
        "  assert model.output_shape == (None, 8, 8, 256) # Note: None is the batch size\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 8, 8, 128)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 16, 16, 64)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 32, 32, 32)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "  assert model.output_shape == (None, 64, 64, 3)\n",
        "  \"\"\"\n",
        "\n",
        "  # Generator using Functional API\n",
        "\n",
        "  # Input layer\n",
        "  input_layer = layers.Input(shape=(100,))\n",
        "  x = layers.Dense(8*8*256, use_bias=False)(input_layer) # input_shape is the noise seed\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "\n",
        "  # Reshape input\n",
        "  reshape = layers.Reshape((8, 8, 256))\n",
        "  x = reshape(x)\n",
        "  # assert reshape.output_shape == (None, 8, 8, 256) # Note: None is the batch size\n",
        "  \n",
        "  # First upscale layer\n",
        "  conv2dtranspose_1 = layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)\n",
        "  x = conv2dtranspose_1(x)\n",
        "  # assert conv2dtranspose_1.output_shape == (None, 8, 8, 128)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "\n",
        "  # Second upscale layer\n",
        "  conv2dtranspose_2 = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
        "  x = conv2dtranspose_2(x)\n",
        "  # assert conv2dtranspose_2.output_shape == (None, 16, 16, 64)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "   \n",
        "  # Third upscale layer\n",
        "  conv2dtranspose_3 = layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
        "  x = conv2dtranspose_3(x)\n",
        "  # assert conv2dtranspose_3.output_shape == (None, 32, 32, 32)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "\n",
        "  # Fourth upscale layer\n",
        "  conv2dtranspose_4 = layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
        "  x = conv2dtranspose_4(x)\n",
        "  # assert conv2dtranspose_4.output_shape == (None, 64, 64, 3)\n",
        "\n",
        "  # Output layer  \n",
        "  output_layer = layers.Activation(activation='tanh')(x)\n",
        "\n",
        "  # Create and compile generator model\n",
        "  model = tf.keras.Model(inputs=[input_layer], outputs=[output_layer], name=\"generator\")\n",
        "  model.compile(loss=generator_loss, optimizer=generator_optimizer)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ao7HxRo6Sw3E",
        "colab": {}
      },
      "source": [
        "def create_discriminator():\n",
        "  \"\"\"\n",
        "  Discriminator using Sequential Model\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(filters=64, kernel_size=(5, 5), strides=(2, 2), padding='same',\n",
        "                                    input_shape=[64, 64, 3]))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(filters=128, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1))\n",
        "  \"\"\"\n",
        "\n",
        "  # Discriminator using Functional API\n",
        "\n",
        "  # Input layer\n",
        "  input_layer = layers.Input(shape=[64, 64, 3])\n",
        "  \n",
        "  # First Convolutional Layer\n",
        "  x = layers.Conv2D(filters=64, kernel_size=(5, 5), strides=(2, 2), padding='same')(input_layer)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "\n",
        "  # Second Convolutional Layer\n",
        "  x = layers.Conv2D(filters=128, kernel_size=(5, 5), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "\n",
        "  # Third Convolutional Layer\n",
        "  x = layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "\n",
        "  # Flatten Layer\n",
        "  x = layers.Flatten()(x)\n",
        "\n",
        "  # Output Layer\n",
        "  output_layer= layers.Dense(1)(x)\n",
        "\n",
        "  # Create and Compile Model\n",
        "  model = tf.keras.Model(inputs=[input_layer], outputs=[output_layer], name=\"discriminator\")\n",
        "  model.compile(loss=discriminator_loss, optimizer=discriminator_optimizer)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I3CCF77cTrmv",
        "outputId": "dd95a4e2-9e5b-478b-8790-7ebac471afd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "#with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "\n",
        "# Testing generator and discriminator without training\n",
        "generator = create_generator() # Create generator model\n",
        "discriminator = create_discriminator() # Create discriminator model\n",
        "\n",
        "# Generate random noise bewteen 1 and 100\n",
        "noise = tf.random.normal([1, 100])\n",
        "\n",
        "# Generate a random image\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "# Plot the generated image\n",
        "plt.imshow(generated_image[0, :, :, 0]) \n",
        "\n",
        "# Discriminate the generated image\n",
        "decision = discriminator(generated_image)\n",
        "\n",
        "# Print the discriminator decision\n",
        "print(decision)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[-0.00114771]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOtq3Y_CjC-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print a summary of the generator model\n",
        "generator.summary()\n",
        "tf.keras.utils.plot_model(generator, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WuafnkLjLIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print a summary of the discriminator model\n",
        "discriminator.summary()\n",
        "tf.keras.utils.plot_model(discriminator, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jueOuDOZhK9",
        "colab_type": "code",
        "outputId": "5cc10d3b-96e2-4baa-8817-0d9ce7cb71a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"checkpoint_dir = '/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'checkpoint_dir = \\'/training_checkpoints\\'\\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\\n                                 discriminator_optimizer=discriminator_optimizer,\\n                                 generator=generator,\\n                                 discriminator=discriminator)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dMfenMQcxAAb"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lkUcBU8xS3fT",
        "colab": {}
      },
      "source": [
        "epochs = 50\n",
        "noise = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# We will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUJmQebDZ2Z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "  noise = tf.random.normal([batch_size, noise_dim])\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = generator(noise, training=True)\n",
        "\n",
        "    real_output = discriminator(images, training=True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cLInlJxZ4ci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "      print(\"bo\")\n",
        "\n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LI3SMDR2K2Mf",
        "colab": {}
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e1_TKKTaJBg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c065c39e-1920-4711-fda6-00f7c926b270"
      },
      "source": [
        "# with tpu_strategy.scope():\n",
        "train(dataset, epochs)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f8409320791e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-2b350323d9ec>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MKFMWzh0Yxsq"
      },
      "source": [
        "## Results"
      ]
    }
  ]
}