{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "FaceGenerator_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds9LpNYOOYHq",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI-Unibo-Projects/Deep-Learning-Project/blob/4_model/FaceGenerator_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QrprJD-R-410"
      },
      "source": [
        "## Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_I0RdnOSkNmi"
      },
      "source": [
        "\n",
        "<h3>  &nbsp;&nbsp;Train on TPU&nbsp;&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a></h3>\n",
        "\n",
        "   1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "   1. Click Runtime again and select **Runtime > Run All**. You can also run the cells manually with Shift-ENTER. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "We'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-RCipesOYHu",
        "colab_type": "code",
        "outputId": "d920e01a-3185-4d51-f5ea-ed354610db37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "tf.keras.backend.clear_session()  # For easy reset of notebook state.\"\"\"\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "    \n",
        "config = tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.2.0-rc3\n",
            "Running on TPU  ['10.67.98.154:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.67.98.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.67.98.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vFIMfPmgQa0h",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmlyV90WGSJ1",
        "colab_type": "code",
        "outputId": "c50432c9-b56f-4a1a-d4da-cce6a6f5390e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "GENERATE_RES = 2 # Generation resolution factor (1=32, 2=64, 3=96, 4=128, etc.)\n",
        "GENERATE_SQUARE = 32 * GENERATE_RES # rows/cols (should be square)\n",
        "IMAGE_CHANNELS = 3\n",
        "\n",
        "# Preview image \n",
        "PREVIEW_ROWS = 4\n",
        "PREVIEW_COLS = 7\n",
        "PREVIEW_MARGIN = 16\n",
        "\n",
        "# Size vector to generate images from\n",
        "SEED_SIZE = 100\n",
        "\n",
        "# Configuration\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync\n",
        "BUFFER_SIZE = 60000\n",
        "\n",
        "IMAGE_SIZE = (GENERATE_SQUARE, GENERATE_SQUARE, IMAGE_CHANNELS)\n",
        "\n",
        "print(f\"Will generate {GENERATE_SQUARE}px square images.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Will generate 64px square images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kvPXiovhi3ZZ"
      },
      "source": [
        "\n",
        "## Input data\n",
        "\n",
        "Our input data is stored on Google Cloud Storage. To more fully use the parallelism TPUs offer us, and to avoid bottlenecking on data transfer, we've stored our input data in TFRecord files, 2025 images per file.\n",
        "\n",
        "Below, we make heavy use of `tf.data.experimental.AUTOTUNE` to optimize different parts of input loading.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LtAVr-4CP1rp",
        "outputId": "011ed54e-4348-4012-af2d-ce05bda6caa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "gcs_pattern = 'gs://celeba-public/tfrecord_*.tfrec'\n",
        "\n",
        "filenames = tf.io.gfile.glob(gcs_pattern)\n",
        "\n",
        "def parse_attribute_list(example):\n",
        "  features = {\n",
        "      \"names\": tf.io.FixedLenFeature([], tf.string),\n",
        "  }\n",
        "\n",
        "  example = tf.io.parse_single_example(example, features)\n",
        "  attributes_names = example['names']\n",
        "  return attributes_names\n",
        "\n",
        "def get_names():\n",
        "  record = tf.data.TFRecordDataset('gs://celeba-test/attribute_list.tfrec')\n",
        "  attributes = record.map(parse_attribute_list)\n",
        "  att_names = next(attributes.as_numpy_iterator()).decode(\"utf-8\")\n",
        "  att_names_list = [elem.strip()[1:-1] for elem in att_names.split(',')]\n",
        "  return att_names_list\n",
        "\n",
        "att_names_list = get_names()\n",
        "\n",
        "\n",
        "feature_dict = {\n",
        "      \"filename\": tf.io.FixedLenFeature([], tf.string),\n",
        "      \"height\": tf.io.FixedLenFeature([], tf.int64),\n",
        "      \"width\": tf.io.FixedLenFeature([], tf.int64),\n",
        "      \"depth\": tf.io.FixedLenFeature([], tf.int64),\n",
        "      \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "  }\n",
        "\n",
        "attributes_dict = dict(zip(att_names_list, [tf.io.FixedLenFeature([], tf.int64) for elem in att_names_list]))\n",
        "\n",
        "feature_dict.update(attributes_dict) \n",
        "\n",
        "def parse_tfrecord(example):\n",
        "  features = feature_dict\n",
        "  example = tf.io.parse_single_example(example, features)\n",
        "  #filename = example['filename']\n",
        "  width = tf.cast(example['width'],tf.int64)\n",
        "  height = tf.cast(example['height'],tf.int64)\n",
        "  decoded = tf.image.decode_image(example['image'])  \n",
        "  normalized = tf.cast(decoded, tf.float32) / 255.0 # convert each 0-255 value to floats in [0, 1] range\n",
        "  image_tensor = tf.reshape(normalized, [height, width, 3])\n",
        "  image_tensor = tf.image.resize(image_tensor[45:173,25:153], (IMAGE_SIZE[0], IMAGE_SIZE[1])) # crop and reshape the image \n",
        "  #attr_dict = {}\n",
        "  #for name in att_names_list:\n",
        "  #  attr_dict[name] = example[name]\n",
        "\n",
        "  #Â return filename, image_tensor, attr_dict\n",
        "  return image_tensor\n",
        "\n",
        "def load_dataset(filenames):\n",
        "  # Read from TFRecords. For optimal performance, we interleave reads from multiple files.\n",
        "  records = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "  return records.map(parse_tfrecord, num_parallel_calls=AUTO)\n",
        "\n",
        "dataset = load_dataset(filenames).prefetch(AUTO).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "train_dist_dataset = tpu_strategy.experimental_distribute_dataset(dataset)\n",
        "print(type(dataset))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KTukaIGil7_m"
      },
      "source": [
        "Let's take a peek at the dataset we've created:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-DwfsJq0l_DJ",
        "colab": {}
      },
      "source": [
        "def display_images(images, n):\n",
        "  plt.figure(figsize=(13,13))\n",
        "  for i in range(n * n):\n",
        "    # define subplot\n",
        "    plt.subplot(n, n, i+1)\n",
        "    # turn off axis\n",
        "    plt.axis('off')\n",
        "    plt.imshow(images[i])\n",
        "  plt.tight_layout()\n",
        "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def get_dataset_iterator(dataset, n_examples):\n",
        "  return dataset.unbatch().batch(n_examples).as_numpy_iterator()\n",
        "\n",
        "training_viz_iterator = get_dataset_iterator(dataset, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JTnyd7qfbYr4",
        "outputId": "279c323c-0044-42de-dd26-edae81567970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"# Re-run this cell to show a new batch of images\n",
        "name, images, attr = next(training_viz_iterator)\n",
        "print('Image name {}\\n'.format(name[0]))\n",
        "for name in attr.keys():\n",
        "  print('{}: {}\\n'.format(name, attr[name][0]))\n",
        "display_images(images, 10)\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"# Re-run this cell to show a new batch of images\\nname, images, attr = next(training_viz_iterator)\\nprint('Image name {}\\n'.format(name[0]))\\nfor name in attr.keys():\\n  print('{}: {}\\n'.format(name, attr[name][0]))\\ndisplay_images(images, 10)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ALtRUlxhw8Vt"
      },
      "source": [
        "## Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5rIcrdGFJXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(seed_size, channels):\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    model.add(layers.Dense(4*4*256,activation=\"relu\",input_dim=seed_size))\n",
        "    model.add(layers.Reshape((4,4,256)))\n",
        "\n",
        "    model.add(layers.UpSampling2D())\n",
        "    model.add(layers.Conv2D(256,kernel_size=3,padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.Activation(\"relu\"))\n",
        "\n",
        "    model.add(layers.UpSampling2D())\n",
        "    model.add(layers.Conv2D(256,kernel_size=3,padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.Activation(\"relu\"))\n",
        "   \n",
        "    # Output resolution, additional upsampling\n",
        "    model.add(layers.UpSampling2D())\n",
        "    model.add(layers.Conv2D(128,kernel_size=3,padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.Activation(\"relu\"))\n",
        "\n",
        "    model.add(layers.UpSampling2D(size=(GENERATE_RES,GENERATE_RES)))\n",
        "    model.add(layers.Conv2D(128,kernel_size=3,padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.Activation(\"relu\"))\n",
        "\n",
        "    # Final CNN layer\n",
        "    model.add(layers.Conv2D(channels,kernel_size=3,padding=\"same\"))\n",
        "    model.add(layers.Activation(\"tanh\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "def build_discriminator(image_shape):\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, padding=\"same\"))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(layers.ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIeUXmrvQ8AT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator():\n",
        "  # Generator using Functional API\n",
        "\n",
        "  # Input layer\n",
        "  input_layer = layers.Input(shape=(100,))\n",
        "  x = layers.Dense(8*8*256, use_bias=False)(input_layer) # input_shape is the noise seed\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "\n",
        "  # Reshape input\n",
        "  reshape = layers.Reshape((8, 8, 256))\n",
        "  x = reshape(x)\n",
        "  # assert reshape.output_shape == (None, 8, 8, 256) # Note: None is the batch size\n",
        "  \n",
        "  # First upscale layer\n",
        "  conv2dtranspose_1 = layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)\n",
        "  x = conv2dtranspose_1(x)\n",
        "  # assert conv2dtranspose_1.output_shape == (None, 8, 8, 128)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "\n",
        "  # Second upscale layer\n",
        "  conv2dtranspose_2 = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
        "  x = conv2dtranspose_2(x)\n",
        "  # assert conv2dtranspose_2.output_shape == (None, 16, 16, 64)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  \n",
        "  # Third upscale layer\n",
        "  conv2dtranspose_3 = layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
        "  x = conv2dtranspose_3(x)\n",
        "  # assert conv2dtranspose_3.output_shape == (None, 32, 32, 32)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "\n",
        "  # Fourth upscale layer\n",
        "  conv2dtranspose_4 = layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
        "  x = conv2dtranspose_4(x)\n",
        "  # assert conv2dtranspose_4.output_shape == (None, 64, 64, 3)\n",
        "\n",
        "  # Output layer  \n",
        "  output_layer = layers.Activation(activation='tanh')(x)\n",
        "\n",
        "  # Create and compile generator model\n",
        "  model = tf.keras.Model(inputs=[input_layer], outputs=[output_layer], name=\"generator\")\n",
        "  # model.compile(loss=generator_loss, optimizer=generator_optimizer)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ao7HxRo6Sw3E",
        "colab": {}
      },
      "source": [
        "def build_discriminator():\n",
        "  # Discriminator using Functional API\n",
        "\n",
        "  # Input layer\n",
        "  input_layer = layers.Input(shape=(64, 64, 3))\n",
        "  \n",
        "  # First Convolutional Layer\n",
        "  x = layers.Conv2D(filters=64, kernel_size=(5, 5), strides=(2, 2), padding='same')(input_layer)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "\n",
        "  # Second Convolutional Layer\n",
        "  x = layers.Conv2D(filters=128, kernel_size=(5, 5), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "\n",
        "  # Third Convolutional Layer\n",
        "  x = layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "\n",
        "  # Flatten Layer\n",
        "  x = layers.Flatten()(x)\n",
        "\n",
        "  # Output Layer\n",
        "  output_layer= layers.Dense(1)(x)\n",
        "\n",
        "  # Create and Compile Model\n",
        "  model = tf.keras.Model(inputs=[input_layer], outputs=[output_layer], name=\"discriminator\")\n",
        "  # model.compile(loss=discriminator_loss, optimizer=discriminator_optimizer)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwYdS0NrZRhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Binary crossentropy losses for generator and discriminator\n",
        "\n",
        "with tpu_strategy.scope():\n",
        "  # Set reduction to `none` so we can do the reduction afterwards and divide by\n",
        "  # global batch size.\n",
        "  loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True,reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "  def generator_loss(fake_output):\n",
        "    per_example_loss = loss_object(tf.ones_like(fake_output), fake_output)\n",
        "    per_example_loss = tf.nn.compute_average_loss(per_example_loss, global_batch_size=BATCH_SIZE)\n",
        "    \n",
        "    return per_example_loss\n",
        "\n",
        "  def discriminator_loss(real_output, fake_output):\n",
        "    per_example_real_loss = loss_object(tf.ones_like(real_output), real_output)\n",
        "    per_example_fake_loss = loss_object(tf.zeros_like(fake_output), fake_output)\n",
        "\n",
        "    per_example_real_loss = tf.nn.compute_average_loss(per_example_real_loss, global_batch_size=BATCH_SIZE)\n",
        "    per_example_fake_loss = tf.nn.compute_average_loss(per_example_fake_loss, global_batch_size=BATCH_SIZE)\n",
        "\n",
        "    total_loss = per_example_real_loss + per_example_fake_loss\n",
        "    return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I3CCF77cTrmv",
        "outputId": "99bd8c6b-7b0f-4617-eb67-67736d73a6e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "# Testing generator and discriminator without training\n",
        "with tpu_strategy.scope(): # Train on TPU\n",
        "  generator = build_generator(SEED_SIZE, IMAGE_CHANNELS) # Create generator model\n",
        "  discriminator = build_discriminator(IMAGE_SIZE) # Create discriminator model\n",
        "  generator_optimizer = tf.keras.optimizers.Adam(1.5e-4, 0.5)\n",
        "  discriminator_optimizer = tf.keras.optimizers.Adam(1.5e-4, 0.5)\n",
        "\n",
        "noise = tf.random.normal([1, SEED_SIZE])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0])\n",
        "\n",
        "# Discriminate the generated image\n",
        "decision = discriminator(generated_image)\n",
        "\n",
        "# Print the discriminator decision\n",
        "print(decision)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.5003638]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOtq3Y_CjC-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print a summary of the generator model\n",
        "generator.summary()\n",
        "tf.keras.utils.plot_model(generator, to_file=\"generator.png\", show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WuafnkLjLIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print a summary of the discriminator model\n",
        "discriminator.summary()\n",
        "tf.keras.utils.plot_model(discriminator, to_file=\"discriminator.png\", show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jueOuDOZhK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"checkpoint_dir = '/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dMfenMQcxAAb"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWkDzkmsXEqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(cnt,noise):\n",
        "  image_array = np.full(( \n",
        "      PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE+PREVIEW_MARGIN)), \n",
        "      PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE+PREVIEW_MARGIN)), 3), \n",
        "      255, dtype=np.uint8)\n",
        "\n",
        "  generated_images = generator.predict(noise)\n",
        "\n",
        "  generated_images = 0.5 * generated_images + 0.5\n",
        "\n",
        "  image_count = 0\n",
        "  for row in range(PREVIEW_ROWS):\n",
        "      for col in range(PREVIEW_COLS):\n",
        "        r = row * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
        "        c = col * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
        "        image_array[r:r+GENERATE_SQUARE,c:c+GENERATE_SQUARE] = generated_images[image_count] * 255\n",
        "        image_count += 1\n",
        "\n",
        "          \n",
        "  output_path = os.path.join(\"\",'output')\n",
        "  if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "  filename = os.path.join(output_path,f\"train-{cnt}.png\")\n",
        "  im = Image.fromarray(image_array)\n",
        "  im.save(filename)\n",
        "\n",
        "def hms_string(sec_elapsed):\n",
        "  h = int(sec_elapsed / (60 * 60))\n",
        "  m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "  s = sec_elapsed % 60\n",
        "  return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lkUcBU8xS3fT",
        "colab": {}
      },
      "source": [
        "fixed_seed = tf.random.normal([BATCH_SIZE, SEED_SIZE])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUJmQebDZ2Z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "\n",
        "def train_step(images):\n",
        "  seed = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = generator(seed, training=True)\n",
        "\n",
        "    real_output = discriminator(images, training = True)\n",
        "    fake_output = discriminator(generated_images, training = True)\n",
        "\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "  return gen_loss, disc_loss\n",
        "\n",
        "@tf.function\n",
        "def distributed_train_step(inputs):\n",
        "  per_replica_gen_losses, per_replica_disc_losses = tpu_strategy.run(train_step, args=(inputs,))\n",
        "  per_replica_gen_losses = tpu_strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_gen_losses, axis=None)\n",
        "  per_replica_disc_losses = tpu_strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_disc_losses, axis=None)\n",
        "  return per_replica_gen_losses, per_replica_disc_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbGZ15OZnGw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    \n",
        "    total_gen_loss = 0.0\n",
        "    total_disc_loss = 0.0\n",
        "    num_batches = 0\n",
        "    \n",
        "    for x in train_dist_dataset:\n",
        "      gen_loss, disc_loss = distributed_train_step(x)\n",
        "      total_gen_loss += gen_loss\n",
        "      total_disc_loss += disc_loss\n",
        "      num_batches += 1\n",
        "\n",
        "    total_gen_loss /= num_batches\n",
        "    total_disc_loss /= num_batches\n",
        "\n",
        "    \"\"\"\n",
        "    i = 1\n",
        "    for batch in dataset:\n",
        "      print(\"Batch\", i)\n",
        "      i = i + 1\n",
        "      train_step(batch)\n",
        "    \"\"\"\n",
        "\n",
        "    template = (\"Epoch {}, Gen Loss: {}, Disc Loss: {}, \"\n",
        "              \"Time: {}\")\n",
        "    print (template.format(epoch+1, total_gen_loss, total_disc_loss, hms_string(time.time()-start)))\n",
        "\n",
        "    save_images(epoch, fixed_seed)\n",
        "\n",
        "    #print(f'Epoch {epoch+1}, gen loss={losses[0]},disc loss={losses[2]}, {time.time()-start}') \n",
        "    #print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # display.clear_output(wait=True)\n",
        "  # generate_and_save_images(generator, epochs, fixed_seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhFwj6IMnLd1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "a1986000-27be-4efb-feb2-283c63ea84ae"
      },
      "source": [
        "train(dataset,EPOCHS)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Gen Loss: 2.5156452655792236, Disc Loss: 11.018026351928711, Time: 0:03:45.91\n",
            "Epoch 2, Gen Loss: 2.5061399936676025, Disc Loss: 11.039400100708008, Time: 0:03:22.51\n",
            "Epoch 3, Gen Loss: 2.5061089992523193, Disc Loss: 11.039563179016113, Time: 0:03:22.20\n",
            "Epoch 4, Gen Loss: 2.5061066150665283, Disc Loss: 11.039151191711426, Time: 0:03:20.24\n",
            "Epoch 5, Gen Loss: 2.5061047077178955, Disc Loss: 11.039630889892578, Time: 0:03:21.22\n",
            "Epoch 6, Gen Loss: 2.5061047077178955, Disc Loss: 11.039541244506836, Time: 0:03:21.58\n",
            "Epoch 7, Gen Loss: 2.5061044692993164, Disc Loss: 11.039461135864258, Time: 0:03:21.10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e82014138ffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-16a66e4572fe>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dist_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistributed_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mtotal_gen_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgen_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36mget_next\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mglobal_has_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_as_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker_devices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m_get_next_as_optional\u001b[0;34m(iterator, strategy, name)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       worker_has_value, next_element = (\n\u001b[0;32m--> 178\u001b[0;31m           iterator._iterators[i].get_next_as_list(new_name))  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    179\u001b[0m       \u001b[0;31m# Collective all-reduce requires explicit devices for inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36mget_next_as_list\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    936\u001b[0m               \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m               \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_dummy_tensor_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m               \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m           )\n\u001b[1;32m    940\u001b[0m           \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   1202\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cond\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m   \u001b[0m__nonzero__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP6Q5Q6t9bXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate a random image\n",
        "generated_image = generator(fixed_seed, training=False)\n",
        "\n",
        "# Plot the generated image\n",
        "plt.imshow(generated_image[0, :, :, 0]) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}