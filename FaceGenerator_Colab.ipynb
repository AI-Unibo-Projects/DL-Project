{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "FaceGenerator_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds9LpNYOOYHq",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI-Unibo-Projects/Deep-Learning-Project/blob/4_model/FaceGenerator_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QrprJD-R-410"
      },
      "source": [
        "## Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_I0RdnOSkNmi"
      },
      "source": [
        "\n",
        "<h3>  &nbsp;&nbsp;Train on TPU&nbsp;&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a></h3>\n",
        "\n",
        "   1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "   1. Click Runtime again and select **Runtime > Run All**. You can also run the cells manually with Shift-ENTER. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "We'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-RCipesOYHu",
        "colab_type": "code",
        "outputId": "bd848d8b-5575-4aaf-de29-e32d7e811318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"is_colab = True\n",
        "try:\n",
        "    import google.colab\n",
        "except:\n",
        "    is_colab = False\"\"\"\n",
        "\n",
        "is_colab = False\n",
        "    \n",
        "if is_colab:\n",
        "    %tensorflow_version 2.x\n",
        "    import tensorflow as tf\n",
        "    print(\"Tensorflow version \" + tf.__version__)\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "    except ValueError:\n",
        "        raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "        \n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    batch_size = 16 * tpu_strategy.num_replicas_in_sync\n",
        "else:\n",
        "    import tensorflow as tf\n",
        "    print(\"Tensorflow version \" + tf.__version__)\n",
        "    batch_size = 16\n",
        "\n",
        "buffer_size = 60000\n",
        "tf.keras.backend.clear_session()  # For easy reset of notebook state."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vFIMfPmgQa0h",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kvPXiovhi3ZZ"
      },
      "source": [
        "\n",
        "## Input data\n",
        "\n",
        "Our input data is stored on Google Cloud Storage. To more fully use the parallelism TPUs offer us, and to avoid bottlenecking on data transfer, we've stored our input data in TFRecord files, 2025 images per file.\n",
        "\n",
        "Below, we make heavy use of `tf.data.experimental.AUTOTUNE` to optimize different parts of input loading.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LtAVr-4CP1rp",
        "outputId": "b974fcfb-a059-4133-a27b-1cf51f86278b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "IMAGE_SIZE = [64, 64]\n",
        "\n",
        "gcs_pattern = 'gs://celeba-public/tfrecord_*.tfrec'\n",
        "\n",
        "filenames = tf.io.gfile.glob(gcs_pattern)\n",
        "\n",
        "def parse_attribute_list(example):\n",
        "  features = {\n",
        "      \"names\": tf.io.FixedLenFeature([], tf.string),\n",
        "  }\n",
        "\n",
        "  example = tf.io.parse_single_example(example, features)\n",
        "  attributes_names = example['names']\n",
        "  return attributes_names\n",
        "\n",
        "def get_names():\n",
        "  record = tf.data.TFRecordDataset('gs://celeba-test/attribute_list.tfrec')\n",
        "  attributes = record.map(parse_attribute_list)\n",
        "  att_names = next(attributes.as_numpy_iterator()).decode(\"utf-8\")\n",
        "  att_names_list = [elem.strip()[1:-1] for elem in att_names.split(',')]\n",
        "  return att_names_list\n",
        "\n",
        "att_names_list = get_names()\n",
        "\n",
        "\n",
        "feature_dict = {\n",
        "      \"filename\": tf.io.FixedLenFeature([], tf.string),\n",
        "      \"height\": tf.io.FixedLenFeature([], tf.int64),\n",
        "      \"width\": tf.io.FixedLenFeature([], tf.int64),\n",
        "      \"depth\": tf.io.FixedLenFeature([], tf.int64),\n",
        "      \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "  }\n",
        "\n",
        "attributes_dict = dict(zip(att_names_list, [tf.io.FixedLenFeature([], tf.int64) for elem in att_names_list]))\n",
        "\n",
        "feature_dict.update(attributes_dict) \n",
        "\n",
        "def parse_tfrecord(example):\n",
        "  features = feature_dict\n",
        "  example = tf.io.parse_single_example(example, features)\n",
        "  #filename = example['filename']\n",
        "  width = tf.cast(example['width'],tf.int64)\n",
        "  height = tf.cast(example['height'],tf.int64)\n",
        "  decoded = tf.image.decode_image(example['image'])  \n",
        "  normalized = tf.cast(decoded, tf.float32) / 255.0 # convert each 0-255 value to floats in [0, 1] range\n",
        "  image_tensor = tf.reshape(normalized, [height, width, 3])\n",
        "  image_tensor = tf.image.resize(image_tensor[45:173,25:153], IMAGE_SIZE) # crop and reshape the image \n",
        "  #attr_dict = {}\n",
        "  #for name in att_names_list:\n",
        "  #  attr_dict[name] = example[name]\n",
        "\n",
        "  #Â return filename, image_tensor, attr_dict\n",
        "  return image_tensor\n",
        "\n",
        "def load_dataset(filenames):\n",
        "  # Read from TFRecords. For optimal performance, we interleave reads from multiple files.\n",
        "  records = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "  return records.map(parse_tfrecord, num_parallel_calls=AUTO)\n",
        "\n",
        "dataset = load_dataset(filenames).batch(batch_size)\n",
        "dataset.shuffle(buffer_size)\n",
        "print(type(dataset))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KTukaIGil7_m"
      },
      "source": [
        "Let's take a peek at the dataset we've created:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-DwfsJq0l_DJ",
        "colab": {}
      },
      "source": [
        "def display_images(images, n):\n",
        "  plt.figure(figsize=(13,13))\n",
        "  for i in range(n * n):\n",
        "    # define subplot\n",
        "    plt.subplot(n, n, i+1)\n",
        "    # turn off axis\n",
        "    plt.axis('off')\n",
        "    plt.imshow(images[i])\n",
        "  plt.tight_layout()\n",
        "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def get_dataset_iterator(dataset, n_examples):\n",
        "  return dataset.unbatch().batch(n_examples).as_numpy_iterator()\n",
        "\n",
        "training_viz_iterator = get_dataset_iterator(dataset, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JTnyd7qfbYr4",
        "outputId": "c3966a5e-5faa-4d08-d937-b172a37fa835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"# Re-run this cell to show a new batch of images\n",
        "name, images, attr = next(training_viz_iterator)\n",
        "print('Image name {}\\n'.format(name[0]))\n",
        "for name in attr.keys():\n",
        "  print('{}: {}\\n'.format(name, attr[name][0]))\n",
        "display_images(images, 10)\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"# Re-run this cell to show a new batch of images\\nname, images, attr = next(training_viz_iterator)\\nprint('Image name {}\\n'.format(name[0]))\\nfor name in attr.keys():\\n  print('{}: {}\\n'.format(name, attr[name][0]))\\ndisplay_images(images, 10)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ALtRUlxhw8Vt"
      },
      "source": [
        "## Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIeUXmrvQ8AT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_generator():\n",
        "  \"\"\"\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(100,))) # input_shape is the noise seed\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Reshape((8, 8, 256)))\n",
        "  assert model.output_shape == (None, 8, 8, 256) # Note: None is the batch size\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 8, 8, 128)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 16, 16, 64)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 32, 32, 32)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "  assert model.output_shape == (None, 64, 64, 3)\n",
        "  \"\"\"\n",
        "\n",
        "  input_layer = layers.Input(shape=(100,))\n",
        "  x = layers.Dense(8*8*256, use_bias=False)(input_layer) # input_shape is the noise seed\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "\n",
        "  reshape = layers.Reshape((8, 8, 256))\n",
        "  x = reshape(x)\n",
        "  # assert reshape.output_shape == (None, 8, 8, 256) # Note: None is the batch size\n",
        "  \n",
        "  conv2dtranspose_1 = layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)\n",
        "  x = conv2dtranspose_1(x)\n",
        "  # assert conv2dtranspose_1.output_shape == (None, 8, 8, 128)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "\n",
        "  conv2dtranspose_2 = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
        "  x = conv2dtranspose_2(x)\n",
        "  # assert conv2dtranspose_2.output_shape == (None, 16, 16, 64)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  \n",
        "  conv2dtranspose_3 = layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
        "  x = conv2dtranspose_3(x)\n",
        "  # assert conv2dtranspose_3.output_shape == (None, 32, 32, 32)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "\n",
        "  conv2dtranspose_4 = layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
        "  x = conv2dtranspose_4(x)\n",
        "  # assert conv2dtranspose_4.output_shape == (None, 64, 64, 3)\n",
        "  output_layer = layers.Activation(activation='tanh')(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs=[input_layer], outputs=[output_layer], name=\"generator\")\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ao7HxRo6Sw3E",
        "colab": {}
      },
      "source": [
        "def create_discriminator():\n",
        "  \"\"\"\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(filters=64, kernel_size=(5, 5), strides=(2, 2), padding='same',\n",
        "                                    input_shape=[64, 64, 3]))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(filters=128, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1))\n",
        "  \"\"\"\n",
        "\n",
        "  input_layer = layers.Input(shape=[64, 64, 3])\n",
        "  \n",
        "  x = layers.Conv2D(filters=64, kernel_size=(5, 5), strides=(2, 2), padding='same')(input_layer)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "\n",
        "  x = layers.Conv2D(filters=128, kernel_size=(5, 5), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "\n",
        "  x = layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "\n",
        "  x = layers.Flatten()(x)\n",
        "  output_layer= layers.Dense(1)(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs=[input_layer], outputs=[output_layer], name=\"discriminator\")\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I3CCF77cTrmv",
        "outputId": "8383724a-23e9-41c7-d47b-ff2cec50cc1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "generator = create_generator()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0])\n",
        "\n",
        "discriminator = create_discriminator()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)\n",
        "\n",
        "generator.summary()\n",
        "discriminator.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.00082181]], shape=(1, 1), dtype=float32)\n",
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 16384)             1638400   \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 16384)             65536     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)   (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "reshape_4 (Reshape)          (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_16 (Conv2DT (None, 8, 8, 128)         819200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_17 (Conv2DT (None, 16, 16, 64)        204800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_18 (Conv2DT (None, 32, 32, 32)        51200     \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_19 (Conv2DT (None, 64, 64, 3)         2400      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 64, 64, 3)         0         \n",
            "=================================================================\n",
            "Total params: 2,782,432\n",
            "Trainable params: 2,749,216\n",
            "Non-trainable params: 33,216\n",
            "_________________________________________________________________\n",
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 32, 32, 64)        4864      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 16, 16, 128)       204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 256)         819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 16385     \n",
            "=================================================================\n",
            "Total params: 1,045,633\n",
            "Trainable params: 1,045,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZT9yDFRY-cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "#with tpu_strategy.scope():\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwYdS0NrZRhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0QTPDZoZUNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W46LXIBNZa5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jueOuDOZhK9",
        "colab_type": "code",
        "outputId": "5cc10d3b-96e2-4baa-8817-0d9ce7cb71a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"checkpoint_dir = '/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'checkpoint_dir = \\'/training_checkpoints\\'\\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\\n                                 discriminator_optimizer=discriminator_optimizer,\\n                                 generator=generator,\\n                                 discriminator=discriminator)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dMfenMQcxAAb"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lkUcBU8xS3fT",
        "colab": {}
      },
      "source": [
        "epochs = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# We will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUJmQebDZ2Z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "  noise = tf.random.normal([batch_size, noise_dim])\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = generator(noise, training=True)\n",
        "\n",
        "    real_output = discriminator(images, training=True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cLInlJxZ4ci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "      print(\"bo\")\n",
        "\n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LI3SMDR2K2Mf",
        "colab": {}
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e1_TKKTaJBg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c065c39e-1920-4711-fda6-00f7c926b270"
      },
      "source": [
        "# with tpu_strategy.scope():\n",
        "train(dataset, epochs)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n",
            "bo\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f8409320791e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-2b350323d9ec>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MKFMWzh0Yxsq"
      },
      "source": [
        "## Results"
      ]
    }
  ]
}