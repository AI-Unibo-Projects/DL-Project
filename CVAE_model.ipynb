{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX-cm9oaC1RG",
        "colab_type": "text"
      },
      "source": [
        "# Project \\#3 - Face generation\n",
        "\n",
        "### Deep Learning course -  A.Y. 2019-2020\n",
        "\n",
        "Students:\n",
        "- Simone Gayed Said\n",
        "- Pierpasquale Colagrande\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GihxzxbDldj",
        "colab_type": "text"
      },
      "source": [
        "## Import of fundamental libraries\n",
        "Herw we import fundamental libraries as TensorFlow, Numpy etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDO_HonUBI7x",
        "colab_type": "code",
        "outputId": "0ae91d03-b6b8-48e3-ee63-585d6f6d2fc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\"\"\"\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\"\"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ntry:\\n  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\\n  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\\nexcept ValueError:\\n  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\\n\\ntf.config.experimental_connect_to_cluster(tpu)\\ntf.tpu.experimental.initialize_tpu_system(tpu)\\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HM5aL38Crbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input, Flatten, Dense, Reshape, Concatenate, Lambda, Concatenate, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import metrics\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vTf8kEYfxIf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Input pipeline\n",
        "\n",
        "Our input data is stored on Google Cloud Storage. To more fully use the parallelism TPUs offer us, and to avoid bottlenecking on data transfer, we've stored our input data in TFRecord files, 2025 images per file.\n",
        "\n",
        "Below, we make heavy use of `tf.data.experimental.AUTOTUNE` to optimize different parts of input loading.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEHyAVAoFyu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 60000\n",
        "ORIGINAL_IMAGE_SIZE = (218, 178, 3)\n",
        "TARGET_IMAGE_SIZE = (64, 64, 3)\n",
        "INTERMEDIATE_SIZE = 3072\n",
        "ATTRIBUTES_SIZE = 40\n",
        "LATENT_DIM = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry2QzPDZpn0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "gcs_pattern = 'gs://celeba-test/tfrecord_*.tfrec'\n",
        "\n",
        "filenames = tf.io.gfile.glob(gcs_pattern)\n",
        "\n",
        "def parse_attribute_list(example):\n",
        "  features = {\n",
        "      \"names\": tf.io.FixedLenFeature([], tf.string),\n",
        "  }\n",
        "\n",
        "  example = tf.io.parse_single_example(example, features)\n",
        "  attributes_names = example['names']\n",
        "  return attributes_names\n",
        "\n",
        "def get_names():\n",
        "  record = tf.data.TFRecordDataset('gs://celeba-test/attribute_list.tfrec')\n",
        "  attributes = record.map(parse_attribute_list)\n",
        "  att_names = next(attributes.as_numpy_iterator()).decode(\"utf-8\")\n",
        "  att_names_list = [elem.strip()[1:-1] for elem in att_names.split(',')]\n",
        "  return att_names_list\n",
        "\n",
        "att_names_list = get_names()\n",
        "\n",
        "feature_dict = {\n",
        "      \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "      \"labels\": tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
        "  }\n",
        "\n",
        "def parse_tfrecord(example):\n",
        "  features = feature_dict\n",
        "  example = tf.io.parse_single_example(example, features)\n",
        "  decoded = tf.image.decode_image(example['image'])  \n",
        "  normalized = tf.cast(decoded, tf.float32) / 255.0 # convert each 0-255 value to floats in [0, 1] range\n",
        "  image_tensor = tf.reshape(normalized, [ORIGINAL_IMAGE_SIZE[0], ORIGINAL_IMAGE_SIZE[1], ORIGINAL_IMAGE_SIZE[2]])\n",
        "  image_tensor = tf.image.resize(image_tensor[45:173,25:153], (TARGET_IMAGE_SIZE[0], TARGET_IMAGE_SIZE[1])) # crop and reshape the image \n",
        "  labels = example['labels']\n",
        "  return  {\"encoder_input\":image_tensor,\"labels\": tf.cast(labels,tf.float32)}\n",
        "\n",
        "\n",
        "def load_dataset(filenames):\n",
        "  # Read from TFRecords. For optimal performance, we interleave reads from multiple files.\n",
        "  records = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "  return records.map(parse_tfrecord, num_parallel_calls=AUTO)\n",
        "\n",
        "\n",
        "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
        "\n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "\n",
        "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "  # Repeat forever\n",
        "  ds = ds.repeat()\n",
        "\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
        "  # is training.\n",
        "  ds = ds.prefetch(buffer_size=AUTO)\n",
        "\n",
        "  return ds\n",
        "\n",
        "image_ds = load_dataset(filenames)\n",
        "training_dataset = prepare_for_training(image_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aoOr26pgNup",
        "colab_type": "text"
      },
      "source": [
        "Let's take a peek at the dataset we've created:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK3IHe5aXlJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_batch(image_batch):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(25):\n",
        "    ax = plt.subplot(5,5,n+1)\n",
        "    plt.imshow(image_batch[n])\n",
        "    plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1uFdQJqXrdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_batch = next(iter(training_dataset))\n",
        "show_batch(image_batch[\"encoder_input\"].numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvs16U9cFztm",
        "colab_type": "text"
      },
      "source": [
        "## Network model\n",
        "Here, we build the network model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZaGJcnMu5uF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sampling(Layer):\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var = inputs\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqirPLzF0nwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"LOSS_FACTOR = 10000\n",
        "def r_loss(y_true, y_pred):\n",
        "  return K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n",
        "\n",
        "def kl_loss(y_true, y_pred):\n",
        "  kl_loss =  -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis = 1)\n",
        "  return kl_loss\n",
        "\n",
        "def total_loss(y_true, y_pred):\n",
        "  return LOSS_FACTOR*r_loss(y_true, y_pred) + kl_loss(y_true, y_pred)\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rYrp03YvJWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_vae():\n",
        "  # Define encoder model.\n",
        "  original_inputs = Input(shape=TARGET_IMAGE_SIZE, name='encoder_input')\n",
        "  labels = Input(shape = (ATTRIBUTES_SIZE,), name='labels')\n",
        "  shape_before_flattening = K.int_shape(original_inputs)[1:] \n",
        "  x = Flatten()(original_inputs)\n",
        "  xy = Concatenate()([x, labels])\n",
        "  h = Dense(INTERMEDIATE_SIZE, activation='relu')(xy)\n",
        "  z_mean = Dense(LATENT_DIM, name='z_mean')(h)\n",
        "  z_log_var = Dense(LATENT_DIM, name='z_log_var')(h)\n",
        "  z = Sampling()((z_mean, z_log_var))\n",
        "\n",
        "\n",
        "  decoder_h = Dense(INTERMEDIATE_SIZE, activation='relu')\n",
        "  decoder_out = Dense(np.prod(TARGET_IMAGE_SIZE), activation='sigmoid')\n",
        "  # Define decoder model.\n",
        "  zy = Concatenate()([z,labels])\n",
        "  dec1 = decoder_h(zy)\n",
        "  x_hat = decoder_out(dec1)\n",
        "  x_hat =  Reshape(shape_before_flattening)(x_hat)\n",
        "\n",
        "  #rec_loss = original_dim * metrics.binary_crossentropy(x, x_hat)\n",
        "  #kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "  #vae_loss = K.mean(rec_loss + kl_loss)\n",
        "\n",
        "  # Add KL divergence regularization loss.\n",
        "  kl_loss = - 0.5 * tf.reduce_mean(\n",
        "      z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
        "\n",
        "  vae = Model(inputs=[original_inputs,labels], outputs=[x_hat], name = \"vae\")\n",
        "  vae.add_loss(kl_loss)\n",
        "  return vae\n",
        "\n",
        "vae = create_vae()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "vae.compile(optimizer,loss=tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "vae.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybA4J8C1D5N6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae.fit(training_dataset, epochs=20, steps_per_epoch=202599//BATCH_SIZE, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}